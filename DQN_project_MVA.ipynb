{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZS05C06iS894",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "metadata": {
        "id": "5A3J1VltTUyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "be741fcf-88c5-4a32-a8ba-be0443dbd77d"
      },
      "cell_type": "code",
      "source": [
        "!pip install sk-video"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sk-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/3f/ce848b8b2062ad1ccf1449094a740c775f6c761339f411e44f1e090f23a7/sk_video-1.1.10-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.3MB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.14.6)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9L_9wwl3S896",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQb7eEbOS8-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "h3rX4MvuS8-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "metadata": {
        "id": "jrkJWg1GS8-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Context"
      ]
    },
    {
      "metadata": {
        "id": "-aaGWG6aS8-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "metadata": {
        "id": "fycdu8vgS8-G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "metadata": {
        "id": "uaQKGP6nS8-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The environment"
      ]
    },
    {
      "metadata": {
        "id": "sRiE9UH5S8-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "metadata": {
        "id": "s6Kt-HjHS8-J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6wTLLGjS8-O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "metadata": {
        "id": "1bs3lyLKS8-O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Agent"
      ]
    },
    {
      "metadata": {
        "id": "7PH0nLLVS8-Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "metadata": {
        "id": "cJG3Qr6tS8-R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eAHOrvi4S8-W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "metadata": {
        "id": "hG3MnA7CS8-W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the training phase (train=True), the function uses the currently learned policy with probability $1-\\epsilon$ and randomly picks an action with probability $\\epsilon$. This is one way to balance exploration and exploitation which is called $\\epsilon$-greedy. (other approaches (UCB) favor less explored actions and states through the higher uncertainies on their estimated discounted reward).\n",
        "\n",
        "The $\\epsilon$ is necessary to perform exploration and form accurate estimates of the Q-function of the current policy in order to improve properly.\n"
      ]
    },
    {
      "metadata": {
        "id": "zcRUzyViS8-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "metadata": {
        "id": "lp7X3-04S8-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "KAe1Pty1S8-Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "metadata": {
        "id": "UJPOUak5S8-b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "metadata": {
        "id": "qTwCLOJkS8-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4L3PFSdaS8-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "metadata": {
        "id": "2dLSmjhFS8-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=15 # set small when debugging\n",
        "epochs_test=15 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHcFXj0eS8-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "metadata": {
        "id": "peoPar1jS8-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "board is a 2D array that stores food values on the NxN grid (+0.5 for cheese and -1 for poisonous cells). And position is a 2D array that stores the current position of the rat (+1 for the current positon, -1 elsewhere)"
      ]
    },
    {
      "metadata": {
        "id": "leAOqRqZS8-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Agent"
      ]
    },
    {
      "metadata": {
        "id": "71cdg_SbS8-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "metadata": {
        "id": "Isyi9akZS8-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        np.random.randint(0, self.n_action, size=1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZM9SbJSiS8-r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "metadata": {
        "id": "6Uy_a_WiS8-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        state = env.reset()\n",
        "        game_over = False\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        while not game_over:\n",
        "            action = agent.act(state)\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "            if reward > 0 :\n",
        "                win += reward\n",
        "            else:\n",
        "                lose -= reward          \n",
        "            loss = agent.reinforce(prev_state, state, action, reward, game_over)\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QS4wOXSuS8-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "0a469a35-ab24-48f2-fb96-eb05543dca6f"
      },
      "cell_type": "code",
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 0.5/4.0. Average score (-3.5)\n",
            "Win/lose count 2.0/2.0. Average score (-1.75)\n",
            "Win/lose count 2.5/2.0. Average score (-1.0)\n",
            "Win/lose count 3.0/2.0. Average score (-0.5)\n",
            "Win/lose count 1.5/1.0. Average score (-0.3)\n",
            "Win/lose count 1.0/3.0. Average score (-0.5833333333333334)\n",
            "Win/lose count 1.5/1.0. Average score (-0.42857142857142855)\n",
            "Win/lose count 1.0/4.0. Average score (-0.75)\n",
            "Win/lose count 1.5/0.0. Average score (-0.5)\n",
            "Win/lose count 2.0/3.0. Average score (-0.55)\n",
            "Win/lose count 1.0/2.0. Average score (-0.5909090909090909)\n",
            "Win/lose count 2.0/3.0. Average score (-0.625)\n",
            "Win/lose count 2.0/2.0. Average score (-0.5769230769230769)\n",
            "Win/lose count 2.5/1.0. Average score (-0.42857142857142855)\n",
            "Win/lose count 1.5/1.0. Average score (-0.36666666666666664)\n",
            "Final score: -0.36666666666666664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "I5Kp8LZKS8-1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "metadata": {
        "id": "aLXPjHqQS8-2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-SEyDPUlS8-3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Answer**\n",
        "***\n",
        "We have: \n",
        "\\begin{align*} \n",
        "Q^\\pi (s,a) &= E_{p^\\pi} [\\sum_{t=0}^\\infty \\gamma^t r(s_t, a_t)|s_0 = s, a_0 = a] \\\\\n",
        " &= E_{p^\\pi} [r(s_0,a_0) + \\gamma \\sum_{t=0}^\\infty \\gamma^t r(s_{t+1}, a_{t+1})|s_0 = s, a_0 = a] \n",
        "\\end{align*}\n",
        "\n",
        "The first term is $E_{p^\\pi} [r(s_0,a_0)|s_0 = s, a_0 = a] = r(s, a)$\n",
        "\n",
        "The second term can be simplified as:\n",
        "\n",
        "\\begin{align*}\n",
        "\\gamma E_{p^\\pi} [\\sum_{t=0}^\\infty \\gamma^t r(s_{t+1}, a_{t+1})|s_0 = s, a_0 = a] &= \\gamma E_{(s',a')\\sim p^\\pi(.|s, a)}[E_{p^\\pi} [\\sum_{t=1}^\\infty \\gamma^t r(s_{t+1}, a_{t+1}) | s_0 = s, s_1=s', a_0=a, a_1=a']]\\\\\n",
        "  \\end{align*}\n",
        "  And using the Markov property, this is equal to:\n",
        " \\begin{align*}\n",
        " \\gamma E_{(s',a')\\sim p^\\pi(.|s, a)}[E_{p^\\pi} [\\sum_{t=0}^\\infty \\gamma^{t-1} r(s_t, a_t) |  s_1=s',  a_1=a']]&=\n",
        " \\gamma E_{(s',a')\\sim p^\\pi(.|s, a)}[Q^\\pi(s',a')]\n",
        " \\end{align*}\n",
        " Which concludes the first question.\n",
        "The previous calculations also show that:\n",
        "\\begin{align*}\n",
        "Q^{\\pi}(s,a)=E_{s'\\sim p(.|s,a)}[r(s,a)+\\gamma v^{\\pi}(s')]\n",
        "\\end{align*}\n",
        "An using the policy improvement theorem, we know that an optimal policy $v^*$ satisfies $v^*(s) = \\mbox{max}_{a}Q^* (s,a)$. This leads to:\n",
        "\n",
        "\\begin{align*}\n",
        "Q^*(s,a) &= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)  +\\gamma v^*(s')] \\\\\n",
        "&=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)  +\\gamma \\max_{a'}Q^*(s',a')]\n",
        "\\end{align*}\n",
        "\n",
        "We minimize $\\mathcal{L}$ in hopes of finding $\\theta$ such that $\\mathcal{L}(\\theta)=0$. The closer this metric is to 0, the closer we are to finding an optimal policy."
      ]
    },
    {
      "metadata": {
        "id": "5FtIqmUwS8-4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "metadata": {
        "id": "cOxaAj6VS8-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory)>self.max_memory:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(len(self.memory))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7Z2bXtiS8-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "metadata": {
        "id": "KI44LKuJS8-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LW33i2uNS8_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "metadata": {
        "id": "MFZ60CNzS8_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s[None, ...]))\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        shape = (1, 5, 5, self.n_state)\n",
        "        for i in range(self.batch_size):\n",
        "            ######## FILL IN\n",
        "            s, n_s, a, r, game_over_  = self.memory.random_access()\n",
        "            q_s_a = self.model.predict(n_s.reshape(shape))\n",
        "            target_q[i] = q_s_a\n",
        "            \n",
        "            if game_over_:\n",
        "                ######## FILL IN\n",
        "                input_states[i] = s\n",
        "                target_q[i,a] = r\n",
        "            else:\n",
        "                ######## FILL IN\n",
        "                q_s_a = self.model.predict(n_s.reshape(shape))\n",
        "                input_states[i] = s\n",
        "                target_q[i,a]   = r  + self.discount*np.max(q_s_a)\n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(keras.layers.Flatten(input_shape=(5,5,self.n_state,)))\n",
        "        model.add(Dense(120,activation ='relu'))\n",
        "        model.add(Dense(40,activation ='relu'))\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BL59W00NS8_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "fde9f758-8e0c-41b3-cfa7-e70eb13c21c3"
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 000/015 | Loss 0.0190 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 001/015 | Loss 0.0048 | Win/lose count 4.5/7.0 (-2.5)\n",
            "Epoch 002/015 | Loss 0.0650 | Win/lose count 3.5/8.0 (-4.5)\n",
            "Epoch 003/015 | Loss 0.0133 | Win/lose count 3.5/7.0 (-3.5)\n",
            "Epoch 004/015 | Loss 0.0148 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 005/015 | Loss 0.0178 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 006/015 | Loss 0.0191 | Win/lose count 9.0/6.0 (3.0)\n",
            "Epoch 007/015 | Loss 0.0102 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 008/015 | Loss 0.0102 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 009/015 | Loss 0.0077 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 010/015 | Loss 0.0099 | Win/lose count 10.0/8.0 (2.0)\n",
            "Epoch 011/015 | Loss 0.0101 | Win/lose count 10.5/10.0 (0.5)\n",
            "Epoch 012/015 | Loss 0.0089 | Win/lose count 7.0/8.0 (-1.0)\n",
            "Epoch 013/015 | Loss 0.0087 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 014/015 | Loss 0.0153 | Win/lose count 5.0/5.0 (0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGPNtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAMZZYiEADv//vb8/AptUwn/LZ/+iL/lb+9P2a61uFE7M7QacwPQC/3cd/Xi1bCrc27LcdG8bJkAU3Roif7wCeUHwPTF9bzPwKauk7PwKShQj/ojhP8GdykWRro2KPjFLlULL/viKAqjDNegvQid3tt+qe2Xw7x+MIc22ALIwstvlyU3W9neTohxTXLpRu6uKOefiAWLdUI8Vt289/QrTBiJGL9J6RL/BTvoWd3DTAUZmIedHU0aQ7l9a2DbRIwR6aBlxld2ILDVbZdXULaaxlllQ5ao1ZSNhxiyxW4N6tlTYFJMM9Imkx0LlhrEx3z8X/50L7NmhXnUUcnDeNPg+Rx3WuhjMOO2gckN7FK96IzccpjObv6q2N6a8rmARf9dajbLjKvxOBuAU5q27sQeAaN8sIpO8xqNiS7BQ9Y68+tEUulXmx6Zn6EioXiipaEAzIY660l6Z1iOtrhd29IPWPcOELpxR8Dzhrpp1G2VYqKRE9P21LXLow51i1m36SpkPu8u+AHgMw9QhJGH6Raq1/1CLm7sWp8LaqFAAvj4JU9LA1Xdltm1P0lxHr1nPqDTh3zGQ2JnMhFlxFIkJ7ghSafOCEzRi5DKBSDN975tl8n+NTQ9Ua78WOdkuAiwEkblm4kzeQ2qlRONyQBO/PFbC6dsVviyjxRWBIQWFmlMjr9lJKAh3Fn3A1wA1Kj0ryr/BnZyd4pJAKGfxbzkpKc9mk6TEsplfJEiI78J7PMFQB9FwKGqtPy3yQcwPXX/xRV+5YD7+rGtzB1+9G9L5vlEQniHfNUDpkK8QDROoTIP/NgsaKGpdQixapJy54iHMDkk7gl44y87zAVO0s5TcIkD61ZJiTKuqdXgfuOVhkBfOOKvYviGtfQ2SWwlwBwKGQvyIR6aS++1JuSqkzczzWHGqreiAKBbSAVKXKqO5TEn73TBzA0+EgTCcS66skKKrLrpzI40kaAHI3m5Kf5chXOx64S9ODMA9YAnIPeXiY1OkPjdDAk6/eBtAZKZVPlqLa1/Yo7vPP4GLE/Ykhqp8rlqNDUFQIsf+AoEqgAtYQAAAA1BmiRsQ7/+qZYAAJWAAAAACkGeQniF/wAAsoEAAAAQAZ5hdEK/AA9ihvZdV/BvwAAAABABnmNqQr8AD2KG9itH3B5BAAAAEkGaaEmoQWiZTAhv//6nhAABJwAAAAxBnoZFESwv/wAAsoEAAAAQAZ6ldEK/AA9ihvZdV/BvwQAAABABnqdqQr8AD2KG9itH3B5AAAAAGUGaq0moQWyZTAhn//6eEABLviHnW6BkiwwAAAASQZ7JRRUsK/8AD4gwCAUwDnJhAAAADgGe6mpCvwAPjX6R7n9+AAAAGUGa7EmoQWyZTAhv//6nhAAS746Y/w+rbs0AAAAYQZsNSeEKUmUwIb/+p4QAEm+jmgrWZTanAAAAHEGbMUnhDomUwIb//qeEABHvjp7vN199bMUI/n8AAAAlQZ9PRRE8L/8AD71WJ8JTc//xCAgMs//xAx2rP/z/ef926h4egQAAABABn250Qr8AFizRInxZikZwAAAAEAGfcGpCvwAWJtyKvAFAU4AAAAAZQZtzSahBaJlMFPDP/p4QAEVVKdtfX329pQAAABABn5JqQr8ADoM8IeNDWWqAAAAAGEGblEnhClJlMCG//qeEABJR8x5GJ/lu1QAAABlBm7dJ4Q6JlMCGf/6eEABu/X39CugVqjrdAAAAEkGf1UURPCv/ABdMHXd39IsqwAAAAA4Bn/ZqQr8AF0bddx4JVwAAABlBm/hJqEFomUwIZ//+nhAARb4h/bIY+sOLAAAAGUGaGUnhClJlMCG//qeEAAuvup+o40JDx8AAAAAZQZo6SeEOiZTAhv/+p4QAB5QeFOs6fde5gQAAABlBmltJ4Q8mUwId//6plgAD5jp+U0Y/WofAAAAAG0Gaf0nhDyZTAhv//qeEAAyLq1TH+rdvsH6+RQAAABBBnp1FETwv/wAHa/h661jBAAAAEAGevHRCvwAKPlqgdO1EIYAAAAAPAZ6+akK/AAo/KwLr/ERAAAAAGkGaokmoQWiZTAhv//6nhAAMn7B/hOC3QrFBAAAAD0GewEURLCv/AAo7bgTkQAAAAA0BnuFqQr8ACj8rDxcjAAAAG0Ga40moQWyZTAhv//6nhAAH99lYzegrWZTgiAAAAB5BmwZJ4QpSZTAhv/6nhAAHy9lYHD3nwW3NnuNjEMEAAAAQQZ8kRTRMK/8ABnCNAwBiYQAAAA8Bn0VqQr8ABkrFgXX+OkEAAAAaQZtJSahBaJlMCG///qeEAAef2D/CcFuhfMEAAAASQZ9nRREsK/8ABkiO3OsnylSAAAAADgGfiGpCvwAGSsQu96sOAAAAHUGbi0moQWyZTBRMN//+p4QAB8F3FILVs/wf5SPBAAAAEAGfqmpCvwAGcdqW4bNrIYAAAAAcQZutSeEKUmUwUsM//p4QADDr7muOfza+vvuCUAAAABABn8xqQr8ACj2EeTA9fFmBAAAAGUGbzknhDomUwIb//qeEAAyfsH+E4LdCsUEAAAAbQZvxSeEPJlMCGf/+nhAAH69cbe9N91n6Nv6BAAAAEkGeD0URPCv/AAbB1b2Fgv0xgAAAAA4BnjBqQr8ABsHXx5wUDAAAABlBmjJJqEFomUwIZ//+nhAAIKIcfzwX8kjFAAAAGUGaU0nhClJlMCGf/p4QADNyGOfoDiO4AcAAAAAYQZp0SeEOiZTAhn/+nhAAT3gxz+HOb65pAAAAG0GalUnhDyZTAhn//p4QAHlKcc/hz4gcP8LegQAAABlBmrZJ4Q8mUwIb//6nhAAw9In+pHRpDXJAAAAAHkGa2EnhDyZTBRE8M//+nhABLRDlW4Lyc5vOrvF6bQAAABABnvdqQr8APizwh40NY52BAAAAGEGa+UnhDyZTAhn//p4QAc8pxz+HOb6zUwAAABlBmxpJ4Q8mUwIb//6nhAB5QeFOs6fdbemBAAAAKEGbPEnhDyZTBRE8N//+p4QAf31huZZXjDPwKZbOz4FCkHzcMr7P83EAAAAQAZ9bakK/AGmdU8lzPkmvgQAAABdBm19J4Q8mUwIZ//6eEAH69ca6rgo7/QAAABJBn31FETwr/wBsHVvYWC/LgYAAAAAQAZ+eakK/AGwdqOV+sUjMwAAAABhBm4BJqEFomUwIZ//+nhAB/fX3hMzUd/kAAAAZQZuhSeEKUmUwIb/+p4QAf34DA3P4W6TSygAAABpBm8NJ4Q6JlMFNEwz//p4QAftWp6N8Q/OOBQAAABABn+JqQr8AbB2pbhs2priAAAAAF0Gb5EnhDyZTAhn//p4QAf3194TM1Hf5AAAAGUGaBUnhDyZTAhv//qeEAH9+AwNz+Fuk0ssAAAAaQZonSeEPJlMFETwz//6eEAH7VqejfEPzjgUAAAAQAZ5GakK/AGwdqW4bNqa4gQAAABdBmkhJ4Q8mUwIZ//6eEAH99feEzNR3+AAAABlBmmlJ4Q8mUwIb//6nhAB/fgMDc/hbpNLKAAAAGkGai0nhDyZTBRE8M//+nhAB+1ano3xD844FAAAAEAGeqmpCvwBsHaluGzamuIAAAAAXQZqsSeEPJlMCGf/+nhAB/fX3hMzUd/gAAAAZQZrNSeEPJlMCG//+p4QAf34DA3P4W6TSywAAABpBmu9J4Q8mUwURPDP//p4QAftWp6N8Q/OOBQAAABABnw5qQr8AbB2pbhs2priBAAAAF0GbEEnhDyZTAhn//p4QAf3194TM1Hf4AAAAGUGbMUnhDyZTAhv//qeEAH9+AwNz+Fuk0soAAAAaQZtTSeEPJlMFETwz//6eEAH7VqejfEPzjgUAAAAQAZ9yakK/AGwdqW4bNqa4gAAAABdBm3RJ4Q8mUwIZ//6eEAH99feEzNR3+AAAABlBm5VJ4Q8mUwIb//6nhAB/fgMDc/hbpNLLAAAAGkGbt0nhDyZTBRE8M//+nhAB+1ano3xD844EAAAAEAGf1mpCvwBsHaluGzamuIEAAAAXQZvYSeEPJlMCGf/+nhAB/fX3hMzUd/kAAAAZQZv5SeEPJlMCG//+p4QAf34DA3P4W6TSygAAABpBmhtJ4Q8mUwURPDf//qeEAIKtpcze6nxbvQAAABABnjpqQr8AbB2pbhs2priAAAAAGkGaPEnhDyZTAhv//qeEAIN8jgE17bpdbdmBAAAAHUGaQEnhDyZTAhv//qeEAMy6tUx/LgGZBqYP49WxAAAAEEGefkURPC//AHmTVv5syqQAAAAPAZ6ddEK/AKP0A6E5LwLAAAAAEAGen2pCvwCoWPLcNm1M6oEAAAAbQZqBSahBaJlMCG///qeEATxAFm2xG5//crKgAAAAHEGao0nhClJlMFESw3/+p4QBPFBvzG69kJ6tC1MAAAAPAZ7CakK/AP6TKZtmRrK2AAAAGUGaxEnhDomUwId//qmWAJj9HPv2Qbin3+EAAAAXQZrnSeEPJlMCHf/+qZYAmCpws5j8QWUAAAASQZ8FRRE8K/8A8rO+sfgvzWzBAAAADgGfJmpCvwDys8Wz9Sq/AAAAGUGbKkmoQWiZTAh3//6plgCY/Rz7/cegsoAAAAASQZ9IRREsK/8A+CuDXHveoOCAAAAADgGfaWpCvwD4AzHoitqTAAAAGUGbbUmoQWyZTAh3//6plgCYL92OCj5ol4AAAAASQZ+LRRUsK/8A8rO+sfgvzWzAAAAADgGfrGpCvwDys8Wz9Sq/AAAAG0GbsEmoQWyZTAhv//6nhAJB0T/UrgMDc/YiHwAAABJBn85FFSwr/wF/duF2G+l5qHkAAAAPAZ/vakK/AX924TggcSpgAAAAFkGb9EmoQWyZTAhv//6nhAJp3U/VIQ8AAAAOQZ4SRRUsL/8BHqACraEAAAAQAZ4xdEK/AYl5N5gljaKRMAAAABABnjNqQr8BetRPIjr+A3LAAAAAHUGaNkmoQWyZTBRMN//+p4QCSeNP3+V4Hg3RTBsxAAAAEAGeVWpCvwGJZua48VbRuWAAAAAYQZpZSeEKUmUwIZ/+nhAEt+If2yGPrCFtAAAAEUGed0U0TCv/AP7NG803vUG3AAAADwGemGpCvwD+lbpRpDxKZgAAABpBmppJqEFomUwIb//+p4QAyPsH+E4LdCRxwQAAABlBmrtJ4QpSZTAhv/6nhAB/fYP8JwW6EllAAAAAGUGa3EnhDomUwId//qmWACt6WVxml/bAUUEAAAAdQZr/SeEPJlMCHf/+qZYAQhFhujEM5+GdsHN86lUAAAASQZ8dRRE8K/8AbB2oEJGP2+PAAAAADgGfPmpCvwBsHarp+pceAAAAHEGbIkmoQWiZTAh3//6plgBCfkdBDOlnR1PIy8EAAAASQZ9ARREsK/8AqGDru7+kVnVAAAAAEAGfYWpCvwCoNfOdaGF4qkEAAAAZQZtmSahBbJlMCG///qeEAMzag7t9g/W/UgAAABRBn4RFFSwv/wB5k6d7aVHBrFdFMQAAABABn6N0Qr8AaYBTPK/JTZ9JAAAAEAGfpWpCvwCoWPHK/tw+ncEAAAASQZuqSahBbJlMCG///qeEAAEnAAAAE0GfyEUVLC//ALomz8zbidMfP7oAAAAQAZ/ndEK/AP8QBztjjTP1IAAAABABn+lqQr8A/s0bzTFW0dfBAAAAGUGb60moQWyZTAhv//6nhADN+wevZnwRXVMAAAAaQZoPSeEKUmUwIb/+p4QAyPsH+eUqVui1qaAAAAAVQZ4tRTRML/8Adr+K4aMBz6LK7RL5AAAAEAGeTHRCvwCjprRklv9bfMEAAAAQAZ5OakK/AGwdU8lzPkmrgQAAABpBmlBJqEFomUwIb//+p4QAzNIn+q4DH4g/wAAAABtBmnRJ4QpSZTAhv/6nhAE0HzVNZtzXjp9qzVgAAAAQQZ6SRTRML/8AujLFQgn90QAAABABnrF0Qr8A/xAHO2ONM/UgAAAADwGes2pCvwD+eaJqSmz5gAAAABpBmrVJqEFomUwIb//+p4QBNfjp9RxoSHBWwQAAABlBmtZJ4QpSZTAh3/6plgBlvaX87pCmERxwAAAAGkGa+knhDomUwIb//qeEAMzYNSDMt9E/Qn0hAAAAFUGfGEURPC//AHmTp3tpSCOnaxXRTQAAABABnzd0Qr8AaYBTPK/JTZ9IAAAAEAGfOWpCvwCoWPHK/tw+ncEAAAAeQZs8SahBaJlMFPDv/qmWAJwUdQgzQKfSqDH/sSasAAAAEAGfW2pCvwD+eaJkTSs2fMEAAAAbQZtASeEKUmUwId/+qZYBI6WcoMz+l2l/WWbNAAAAEEGffkU0TC//ARagOXkT6CAAAAAQAZ+ddEK/AX+TQifFmKNQ8AAAAA8Bn59qQr8BiQWNgcpsqYEAAAASQZuESahBaJlMCG///qeEAAEnAAAADEGfokURLC//AACygQAAABABn8F0Qr8BetRPJsB9ulXAAAAAEAGfw2pCvwGJBY19UHTyypkAAAAdQZvGSahBbJlMFEw7//6plgEn8kvxMWoFoph+pd0AAAAQAZ/lakK/AX8mSab6SDiVMQAAABFBm+pJ4QpSZTAhv/6nhAABJwAAAAxBnghFNEwv/wAAsoAAAAAPAZ4ndEK/AP7cd0dt8KltAAAADwGeKWpCvwD+eaILUeXSbwAAABJBmi5JqEFomUwIZ//+nhAABHwAAAAMQZ5MRREsL/8AALKAAAAADwGea3RCvwD+3HdHbfCpbQAAAA8Bnm1qQr8A/nmiC1Hl0m8AAAAZQZpvSahBbJlMCG///qeEATX46Y/w+rbZQwAAABhBmpBJ4QpSZTAhv/6nhAEt+OmP8Pq22U0AAAAZQZqxSeEOiZTAh3/+qZYBFBMN0VSFHyErYAAAAB5BmtVJ4Q8mUwId//6plgPxLOUGZ8Yb6vjLZR6mSccAAAARQZ7zRRE8L/8BshrdBOCYbMAAAAAQAZ8SdEK/Al9isWxsEl4wIAAAABABnxRqQr8CPrANyPX7952BAAAAE0GbGUmoQWiZTAh3//6plgAAlYAAAAAMQZ83RREsL/8AALKBAAAAEAGfVnRCvwI+sA3SAPt3XcEAAAAQAZ9YakK/Aj6wDcj1+/edgAAAABNBm11JqEFsmUwId//+qZYAAJWBAAAADEGfe0UVLC//AACygAAAABABn5p0Qr8CPrAN0gD7d13BAAAAEAGfnGpCvwI+sA3I9fv3nYEAAAASQZuBSahBbJlMCG///qeEAAEnAAAADEGfv0UVLC//AACygAAAABABn950Qr8CPrAN0gD7d13BAAAAEAGfwGpCvwI+sA3I9fv3nYAAAAASQZvFSahBbJlMCGf//p4QAAR9AAAADEGf40UVLC//AACygAAAABABngJ0Qr8CPrAN0gD7d13BAAAADwGeBGpCvwJdzhooZ9GxZQAAABlBmgZJqEFsmUwIZ//+nhAcfObOt0Cz9hdxAAAAGEGaJ0nhClJlMCGf/p4QGV393ac3ZRMMCQAAABxBmklL4QhDokRggoB/IB/YeAU0TCv//jhAABFwAAAAJAGeaGpCvwKvY+1BxOgisSFJWz92Qt5QdbUnIyrO+9F8Fk4mYAAAC2htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAKknRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACgptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAm1bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJdXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFQGN0dHMAAAAAAAAApgAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAQAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAABQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAwAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAwAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFzgAAABEAAAAOAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHQAAABYAAAASAAAAHQAAABwAAAAgAAAAKQAAABQAAAAUAAAAHQAAABQAAAAcAAAAHQAAABYAAAASAAAAHQAAAB0AAAAdAAAAHQAAAB8AAAAUAAAAFAAAABMAAAAeAAAAEwAAABEAAAAfAAAAIgAAABQAAAATAAAAHgAAABYAAAASAAAAIQAAABQAAAAgAAAAFAAAAB0AAAAfAAAAFgAAABIAAAAdAAAAHQAAABwAAAAfAAAAHQAAACIAAAAUAAAAHAAAAB0AAAAsAAAAFAAAABsAAAAWAAAAFAAAABwAAAAdAAAAHgAAABQAAAAbAAAAHQAAAB4AAAAUAAAAGwAAAB0AAAAeAAAAFAAAABsAAAAdAAAAHgAAABQAAAAbAAAAHQAAAB4AAAAUAAAAGwAAAB0AAAAeAAAAFAAAABsAAAAdAAAAHgAAABQAAAAeAAAAIQAAABQAAAATAAAAFAAAAB8AAAAgAAAAEwAAAB0AAAAbAAAAFgAAABIAAAAdAAAAFgAAABIAAAAdAAAAFgAAABIAAAAfAAAAFgAAABMAAAAaAAAAEgAAABQAAAAUAAAAIQAAABQAAAAcAAAAFQAAABMAAAAeAAAAHQAAAB0AAAAhAAAAFgAAABIAAAAgAAAAFgAAABQAAAAdAAAAGAAAABQAAAAUAAAAFgAAABcAAAAUAAAAFAAAAB0AAAAeAAAAGQAAABQAAAAUAAAAHgAAAB8AAAAUAAAAFAAAABMAAAAeAAAAHQAAAB4AAAAZAAAAFAAAABQAAAAiAAAAFAAAAB8AAAAUAAAAFAAAABMAAAAWAAAAEAAAABQAAAAUAAAAIQAAABQAAAAVAAAAEAAAABMAAAATAAAAFgAAABAAAAATAAAAEwAAAB0AAAAcAAAAHQAAACIAAAAVAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAATAAAAHQAAABwAAAAgAAAAKAAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "hVb--LFBS8_J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "metadata": {
        "id": "nCgDzqFPS8_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(5,5,self.n_state),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "        model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation=\"relu\"))\n",
        "        model.add(keras.layers.Flatten())\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fO5W2bUS8_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "c80b3631-ca42-42cf-e9e9-06d8d694d4b3"
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/015 | Loss 0.0051 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 001/015 | Loss 0.0058 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 002/015 | Loss 0.0077 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 003/015 | Loss 0.0726 | Win/lose count 7.0/13.0 (-6.0)\n",
            "Epoch 004/015 | Loss 0.0080 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 005/015 | Loss 0.0103 | Win/lose count 8.0/5.0 (3.0)\n",
            "Epoch 006/015 | Loss 0.0043 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 007/015 | Loss 0.0637 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 008/015 | Loss 0.0055 | Win/lose count 13.0/3.0 (10.0)\n",
            "Epoch 009/015 | Loss 0.0050 | Win/lose count 19.0/2.0 (17.0)\n",
            "Epoch 010/015 | Loss 0.0689 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 011/015 | Loss 0.0104 | Win/lose count 16.0/8.0 (8.0)\n",
            "Epoch 012/015 | Loss 0.0096 | Win/lose count 17.5/2.0 (15.5)\n",
            "Epoch 013/015 | Loss 0.0029 | Win/lose count 17.0/7.0 (10.0)\n",
            "Epoch 014/015 | Loss 0.0095 | Win/lose count 7.5/6.0 (1.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "CCW01n7ES8_O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "metadata": {
        "id": "cpj6_I-uS8_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "f0ec6e8e-6ed1-4852-864e-e6a80f8bf7e0"
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 2.5/3.0. Average score (-0.5)\n",
            "Win/lose count 6.5/5.0. Average score (0.5)\n",
            "Win/lose count 3.0/3.0. Average score (0.3333333333333333)\n",
            "Win/lose count 2.5/3.0. Average score (0.125)\n",
            "Win/lose count 2.5/4.0. Average score (-0.2)\n",
            "Win/lose count 4.5/1.0. Average score (0.4166666666666667)\n",
            "Win/lose count 7.5/6.0. Average score (0.5714285714285714)\n",
            "Win/lose count 1.0/4.0. Average score (0.125)\n",
            "Win/lose count 4.0/2.0. Average score (0.3333333333333333)\n",
            "Win/lose count 9.0/5.0. Average score (0.7)\n",
            "Win/lose count 8.5/4.0. Average score (1.0454545454545454)\n",
            "Win/lose count 13.5/6.0. Average score (1.5833333333333333)\n",
            "Win/lose count 9.5/5.0. Average score (1.8076923076923077)\n",
            "Win/lose count 5.5/8.0. Average score (1.5)\n",
            "Win/lose count 3.0/7.0. Average score (1.1333333333333333)\n",
            "Final score: 1.1333333333333333\n",
            "Test of the FC\n",
            "Win/lose count 3.5/3.0. Average score (0.5)\n",
            "Win/lose count 2.5/3.0. Average score (0.0)\n",
            "Win/lose count 1.5/3.0. Average score (-0.5)\n",
            "Win/lose count 4.0/0.0. Average score (0.625)\n",
            "Win/lose count 4.5/2.0. Average score (1.0)\n",
            "Win/lose count 7.0/6.0. Average score (1.0)\n",
            "Win/lose count 4.5/7.0. Average score (0.5)\n",
            "Win/lose count 4.5/2.0. Average score (0.75)\n",
            "Win/lose count 4.0/3.0. Average score (0.7777777777777778)\n",
            "Win/lose count 3.5/2.0. Average score (0.85)\n",
            "Win/lose count 7.5/4.0. Average score (1.0909090909090908)\n",
            "Win/lose count 10.0/7.0. Average score (1.25)\n",
            "Win/lose count 4.0/5.0. Average score (1.0769230769230769)\n",
            "Win/lose count 4.5/6.0. Average score (0.8928571428571429)\n",
            "Win/lose count 4.5/7.0. Average score (0.6666666666666666)\n",
            "Final score: 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IT8KYdmiS8_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "74339877-46e2-449c-e1a7-818da1a6b8bd"
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "cV40937rS8_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXp1O8o2S8_a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "I tried to track the performance of each model while changing the temperature parameter. I noticed that CNN does better than FCN for almost all temperatures, however, it requires more time to train. This improvement from FCN to CNN is more noticeable with higher temperatures.\n"
      ]
    },
    {
      "metadata": {
        "id": "2YxS5xR8S8_a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2mQs6mfPS8_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    decay = 0.85\n",
        "    \n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        agent.set_epsilon(agent.epsilon*decay)  # Epsilon greedy policy\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "   \n",
        "        \n",
        "class EnvironmentExploring(Environment):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        super(EnvironmentExploring, self).__init__(grid_size, max_time, temperature)\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        \n",
        "    def act(self, action , train = True):\n",
        "        state, reward, game_over = super(EnvironmentExploring,self).act(action)\n",
        "        # Exploration\n",
        "        if train:\n",
        "            reward -= self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1        \n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(         self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(      self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "        return state, reward, game_over\n",
        "    \n",
        "    def reset(self):\n",
        "        _ = super(EnvironmentExploring,self).reset()\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))    \n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(         self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(      self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ncGEn0lS8_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "59549baa-55cb-4e16-e030-cc51e82d62f1"
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.6, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/015 | Loss 0.0153 | Win/lose count 7.0/21.900000000000052 (-14.900000000000052)\n",
            "Epoch 001/015 | Loss 0.0202 | Win/lose count 6.0/25.7000000000001 (-19.7000000000001)\n",
            "Epoch 002/015 | Loss 0.0120 | Win/lose count 5.5/24.20000000000007 (-18.70000000000007)\n",
            "Epoch 003/015 | Loss 0.0250 | Win/lose count 7.5/30.60000000000012 (-23.10000000000012)\n",
            "Epoch 004/015 | Loss 0.0194 | Win/lose count 11.0/18.400000000000002 (-7.400000000000002)\n",
            "Epoch 005/015 | Loss 0.0112 | Win/lose count 7.5/23.200000000000053 (-15.700000000000053)\n",
            "Epoch 006/015 | Loss 0.0311 | Win/lose count 16.5/17.19999999999998 (-0.6999999999999815)\n",
            "Epoch 007/015 | Loss 0.0212 | Win/lose count 8.5/20.30000000000002 (-11.800000000000018)\n",
            "Epoch 008/015 | Loss 0.0142 | Win/lose count 10.0/17.79999999999999 (-7.79999999999999)\n",
            "Epoch 009/015 | Loss 0.0099 | Win/lose count 17.5/17.19999999999998 (0.3000000000000185)\n",
            "Epoch 010/015 | Loss 0.0151 | Win/lose count 16.5/15.09999999999997 (1.4000000000000306)\n",
            "Epoch 011/015 | Loss 0.0305 | Win/lose count 12.0/19.099999999999977 (-7.0999999999999766)\n",
            "Epoch 012/015 | Loss 0.0207 | Win/lose count 16.5/16.799999999999972 (-0.2999999999999723)\n",
            "Epoch 013/015 | Loss 0.0224 | Win/lose count 19.5/18.99999999999998 (0.5000000000000213)\n",
            "Epoch 014/015 | Loss 0.0230 | Win/lose count 18.5/14.09999999999997 (4.4000000000000306)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "Pdv8n299S8_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e1e242ea-1b64-4bb5-fb0e-64e0bad927af"
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 21.5/20.20000000000002. Average score (1.2999999999999794)\n",
            "Win/lose count 18.5/15.999999999999977. Average score (1.9000000000000012)\n",
            "Win/lose count 16.5/14.29999999999997. Average score (2.000000000000011)\n",
            "Win/lose count 18.5/15.999999999999972. Average score (2.125000000000016)\n",
            "Win/lose count 22.5/13.799999999999978. Average score (3.4400000000000177)\n",
            "Win/lose count 23.0/23.700000000000053. Average score (2.7500000000000058)\n",
            "Win/lose count 21.0/22.000000000000043. Average score (2.214285714285713)\n",
            "Win/lose count 23.5/16.499999999999982. Average score (2.8125000000000013)\n",
            "Win/lose count 19.0/17.19999999999999. Average score (2.700000000000003)\n",
            "Win/lose count 18.5/18.699999999999992. Average score (2.4100000000000033)\n",
            "Win/lose count 17.0/18.100000000000005. Average score (2.090909090909094)\n",
            "Win/lose count 24.0/14.699999999999969. Average score (2.6916666666666718)\n",
            "Win/lose count 29.0/14.099999999999977. Average score (3.6307692307692374)\n",
            "Win/lose count 25.0/14.29999999999997. Average score (4.135714285714294)\n",
            "Win/lose count 23.5/16.799999999999983. Average score (4.3066666666666755)\n",
            "Final score: 4.3066666666666755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "elgeBmkSS8_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "metadata": {
        "id": "vWPbsdTVS8_j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "9Gp5oxVJS8_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    }
  ]
}